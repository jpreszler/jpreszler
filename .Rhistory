ggplot()+geom_polygon(data=world,aes(x=long, y=lat, group=group, map_id=region), fill="white", col="black")
ggplot()+geom_polygon(data=world,aes(x=long, y=lat, group=group), fill="white", col="black")
usa <- map_data('usa')
?map_data
maps::county()
w2 <- gather(weather, key="day", value="val")
w2na <- gather(weather, key="day", value="val", na.rm = TRUE)
View(w2)
w2 <- gather(weather, key="day", value="val", X1:X31)
w2na <- gather(weather, key="day", value="val", X1:X31, na.rm=TRUE)
View(w2na)
w3 <- spread(w2, key=measure, value=val)
View(w3)
w3na <- spread(w2na, key=measure, value=val)
View(w3na)
w2 <- w2[,-1]
w3 <- spread(w2, key=measure, value=val)
View(w3)
?spread
df1 <- data.frame(A=1:5, B=1:5)
df2 <- data.frame(A=1:3, C=1:3)
left_join(df1,df2)
library(dplyr)
left_join(df1,df2)
inner_join(df1,df2)
full_join(df1,df2)
df2$A <- c(1:3,6,7)
df2 <- data.frame(A=c(1:3,6,7), C=c(1:3,7,8))
left_join(df1,df2)
right_join(df1,df2)
full_join(df1,df2)
df3 <- data.frame(A=c(1,1,2,3,3,8), D=c(1:6))
left_join(df1,df3)
full_join(df1,df3)
install.packages("gutenbergr")
install.packages("tidytext")
library(gutenbergr)
gutenberg_authors()
gutenberg_authors
gutenberg_works(author=="Melville, Herman")
moby <- gutenberg_download(15)
head(moby)
moby <- gutenberg_download(2701)
head(moby, 20)
moby <- gutenberg_download(2489)
head(moby, 20)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(tidytext)
mobyWords <- unnest_tokens(moby, word, text)
View(mobyWords)
head(mobyWords)
mobyWordsReduced <- anti_join(mobyWords, stop_words)
mobyWords %>% count(sort=TRUE) %>% head()
mobyWords[,2] %>% count(sort=TRUE) %>% head()
mobyWords %>% count(word,sort=TRUE) %>% head()
mobyWordsReduced %>% count(word,sort=TRUE) %>% head()
library(wordcloud)
wordcloud(mobyWordsReduced)
unique(mobyWordsReduced)
unique(mobyWordsReduced$word)
unique(mobyWordsReduced$word) %>% length()
mobyWRCount <- mobyWordsReduced %>% count(word) %>% ungroup()
wordcloud(mobyWRCount)
wordcloud(mobyWRCount$word, mobyWRCount$n)
wordcloud(mobyWRCount$word, mobyWRCount$n, random.order = FALSE, max.words = 75)
devtools::install_github("lchiffon/wordcloud2")
install.packages("wordcloud2")
mobyWordsReduced %>%  inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 100)
mobyWordsReduced %>%  inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE)
library(gganimate)
head(diamonds)
ggplot(diamonds, aes(x=carat, y=price, col=cut))+geom_point(alpha=.2)+labs(title='Color: {frame_state}')+transition_states(color)+ease_aes('linear')
install.packages("gifski")
install.packages("gifski")
ggplot(diamonds, aes(x=carat, y=price, col=cut))+geom_point(alpha=.2)+labs(title='Color: {frame_state}')+transition_states(color)+ease_aes('linear')
warnings()
ggplot(diamonds, aes(x=carat, y=price, col=cut))+geom_point(alpha=.2)+labs(title='Color: {frame}')+transition_states(color)+ease_aes('linear')
bmi_clean <- read.csv("~/github-web/csc285/small-datasets/bmi_clean.csv", header=FALSE)
View(bmi_clean)
bmi_clean <- read.csv("~/github-web/csc285/small-datasets/bmi_clean.csv")
View(bmi_clean)
library(tidyr)
bmi <- gather(bmi_clean, key="year", value = "bmi", -Country)
bmi$year <- stringr::str_remove(bmi$year, "Y") %>% as.numeric()
ggplot(bmi, aes(y=bmi))+geom_violin()+transition_time(year)
ggplot(bmi, aes(x=bmi))+geom_violin()+transition_time(year)
ggplot(bmi, aes(x=bmi))+geom_boxplot()+transition_time(year)
ggplot(bmi, aes(y=bmi))+geom_boxplot()+transition_time(year)
ggplot(bmi, aes(y=bmi))+geom_boxplot()+labs(title='Year: {frame_time}')+transition_time(year)
library(rvest)
u <- read_html("www.gouletpens.com/collections/pelikan/")
u <- read_html("http://www.gouletpens.com/collections/pelikan/")
u
links <- html_nodes(u, 'a')
linkText <- html_text(links)
linkUrl <- html_attr(links, 'href')
View(links)
linkText
linkUrl
u <- read_html("http://www.rbloggers.com")
links <- html_nodes(u, 'a')
linkText <- html_text(links)
linkUrl <- html_attr(links, 'href')
u <- read_html("http://www.r-bloggers.com")
links <- html_nodes(u, 'a')
linkText <- html_text(links)
linkUrl <- html_attr(links, 'href')
linkUrl
?html_table
u <- read_html("https://projects.fivethirtyeight.com/soccer-predictions/premier-league/")
html_table(u)
html_table(u, fill=TRUE)
births <- read_html("https://www.ssa.gov/oact/babynames/numberUSbirths.html")
html_table(html_nodes(births, "table")[[2]])
births <- read_html("https://www.ssa.gov/oact/babynames/numberUSbirths.html")
btab<-html_table(html_nodes(births, "table")[[2]])
View(btab)
library(ggplot2)
names(btab)
ggplot(btab, aes(x=`Year ofbirth`, y=Total))+geom_line()
ggplot(btab, aes(x=`Year ofbirth`, y=as.numeric(Total)))+geom_line()
btl <- tidyr::gather(btab, key="gender", value="count", -`Year ofbirth`)
btl <- rename(btl, year=`Year ofbirth`)
library(dplyr)
library(stringr)
btl <- rename(btl, year=`Year ofbirth`)
btl <- mutate(count = str_remove_all(count, ","))
btl <- mutate(btl,count = str_remove_all(count, ","))
head(btl)
btl$count <- as.numeric(btl$count)
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line()
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line_interactive(aes(tooltip=year))
install.packages("ggiraph")
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line_interactive(aes(tooltip=year))
library(ggiraph)
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line_interactive(aes(tooltip=year))
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line_interactive(aes(tooltip=year)) %>% ggiraph::ggiraph()
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_line_interactive(aes(tooltip=year)) -> p
girafe(code=print(p))
ggiraph(print(p))
devtools::install_github('davidgohel/ggiraph')
ggplot(filter(btl, gender!= "Total"), aes(x=year, y=count, col=gender))+geom_point_interactive(aes(tooltip=year)) -> p
ggiraph(print(p))
library(dplyr)
library(ggplot2)
library(tidyr)
library(gganimate)
county_population <- read.csv("~/Downloads/county_population.csv")
View(county_population)
map_data("county")
woiun_map <- map_data("county") %>% filter(region %in% c("washington", "oregon", "utah", "idaho", "nevada"))
county_pop <- county_population %>% filter(state_name %in% c("Washington", "Oregon", "Utah", "Idaho", "Nevada")) %>% select(1:6, 11:58)
ggplot(woiun_map, aes(x=lon, y=lat, group=group))+geom_polygon()
ggplot(woiun_map, aes(x=long, y=lat, group=group))+geom_polygon()
ggplot(woiun_map, aes(x=long, y=lat, group=group))+geom_polygon(color="black", fill="white")
library(plotly)
plot_ly(woiun_map, x=~lon, y=~lat, group=~group) %>% add_polygons()
plot_ly(woiun_map, x=~lon, y=~lat) %>%group_by(group) %>% add_polygons()
plot_ly(woiun_map, x=~long, y=~lat) %>%group_by(group) %>% add_polygons()
View(woiun_map)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
#for map_data
states_l <- c("washington", "oregon", "utah", "idaho", "nevada", "arizona", "california")
#for census pop data
states_u <- c("Washington", "Oregon", "Utah", "Idaho", "Nevada", "Arizona", "California")
#get map data
western_map <- map_data("county") %>% filter(region %in% states_l)
#get pop data
county_pop <- read.csv("../small-datasets/county_population.csv", header=TRUE) %>% filter(state_name %in% states_u)
county_pop %>% head() %>% knitr::kable()
View(county_pop)
library(stringr)
filter(county_pop, !str_detect(county_name, "County"))
#get pop data
county_pop <- read.csv("../small-datasets/county_population.csv", header=TRUE) %>% filter(state_name %in% states_u, !(county_name %in% states_u)) %>% select(4:6, 11:58)
filter(county_pop, !str_detect(county_name, "County"))
#clean county_name
county_pop <- mutate(county_pop, county_name = str_remove(county_name, "County") %>% str_to_lower())
#tidy populations
county_pop <- gather(county_pop, key="year", value="population", -c("areaname", "state_name", "county_name"))
View(county_pop)
#tidy populations
county_pop <- county_pop %>%
gather(key="year", value="population", -c("areaname", "state_name", "county_name")) %>%
mutate(year = str_remove(year, "pop") %>% as.numeric())
#get pop data
county_pop <- read.csv("../small-datasets/county_population.csv", header=TRUE) %>% filter(state_name %in% states_u, !(county_name %in% states_u)) %>% select(4:6, 11:43)
#clean county_name
county_pop <- mutate(county_pop, county_name = str_remove(county_name, "County") %>% str_to_lower())
#tidy populations
county_pop <- county_pop %>%
gather(key="year", value="population", -c("areaname", "state_name", "county_name")) %>%
mutate(year = str_remove(year, "pop") %>% as.numeric())
ggplot(county_pop, aes(x=year, y=population, group=county_name))+geom_line()+facet_wrap(.~state_name)
ggplot(county_pop, aes(x=year, y=population, group=county_name))+geom_line()+facet_wrap(.~state_name, scales = "free_y")
ggplot(county_pop, aes(x=year, y=population, group=county_name))+geom_line()+facet_wrap(.~state_name, scales = "free_y")+scale_y_log10()
ggplot(county_pop, aes(x=year, y=population, group=county_name))+geom_line()+facet_wrap(.~state_name, scales = "free_y")+scale_y_log10()
ggplot(county_pop, aes(x=year, y=population, group=county_name))+geom_line()+facet_wrap(.~state_name, scales = "free_y")+scale_y_log10()+transition_time(year)+ease_aes('linear')
ggplot(county_pop, aes(x=year, y=population))+geom_point()+facet_wrap(.~state_name, scales = "free_y")+scale_y_log10()+transition_time(year)+ease_aes('linear')
#get geographic info
county_area <- read.csv("../small-datasets/county-area-2010.csv", header=TRUE, skip=1)
View(county_area)
#get geographic info
county_area <- read.csv("../small-datasets/county-area-2010.csv", header=TRUE, skip=1) %>% select(6:7,9:14)
#get geographic info
county_area <- read.csv("../small-datasets/county-area-2010.csv", header=TRUE, skip=1) %>% select(6:7,10:12)
names(county_area) <- c("state_name", "county_name", "total_area", "water_area", "land_area")
str_extract(county_area$state_name, "- [:alpha:] -")
str_extract(county_area$state_name, "\- [:alpha:] \-")
str_extract(county_area$state_name, '\- [:alpha:] \-')
?str_extract
str_split(county_area, "-", n=3, simplify = TRUE)[,2]
str_split(county_area$state_name, "-", n=3, simplify = TRUE)[,2]
county_area <- county_area %>%
mutate(state_name = str_split(state_name, "-", n=3, simplify = TRUE)[,2] %>%
str_trim(side="both")) %>% filter(state_name %in% state_u)
county_area <- county_area %>%
mutate(state_name = str_split(state_name, "-", n=3, simplify = TRUE)[,2] %>%
str_trim(side="both")) %>% filter(state_name %in% states_u)
View(county_area)
county_area <- county_area %>%
mutate(state_name = str_split(state_name, "-", n=3, simplify = TRUE)[,2] %>%
str_trim(side="both")) %>% filter(state_name %in% states_u, !(county_name %in% states_u))
#get geographic info
county_area <- read.csv("../small-datasets/county-area-2010.csv", header=TRUE, skip=1) %>% select(6:7,10:12)
names(county_area) <- c("state_name", "county_name", "total_area", "water_area", "land_area")
county_area <- county_area %>%
mutate(state_name = str_split(state_name, "-", n=3, simplify = TRUE)[,2] %>%
str_trim(side="both")) %>% filter(state_name %in% states_u, !(county_name %in% states_u)) %>%
mutate(county_name = str_remove(county_name, "County") %>% str_to_lower())
#join
county_data <- inner_join(county_pop, county_area, by=c("state_name", "county_name"))
View(county_data)
county_data <- county_data %>%
mutate(pop_land_density = population/land_area)
base <- ggplot(western_map, mapping=aes(x=long, y=lat, group=subregion))+
geom_polygon(col="black", fill="white")+theme_void()
base
all_data <- inner_join(weatern_map, county_data, by=c("subregion"="county_name"))
all_data <- inner_join(weatern_map, county_data, by=c("subregion"="county_name"))
all_data <- inner_join(western_map, county_data, by=c("subregion"="county_name"))
ggplot(western_map, mapping=aes(x=long, y=lat, group=group, fill=population))+
geom_polygon(col="black")+theme_void()+transition_time(year)+ease_aes('linear')
View(all_data)
ggplot(all_data, mapping=aes(x=long, y=lat, group=group, fill=population))+
geom_polygon(col="black")+theme_void()+transition_time(year)+ease_aes('linear')
library(transformr)
install.packages("transformr")
devtools::install_github("thomasp85/transformr")
devtools::install_github("thomasp85/transformr")
plot_ly(all_data, x=~long, y=~lat, color=~population, frame=~year) %>%group_by(group) %>% add_polygons()
View(all_data)
View(county_data)
#get map data
western_map <- map_data("county") %>% filter(region %in% states_l)
#get pop data
county_pop <- read.csv("../small-datasets/county_population.csv", header=TRUE) %>% filter(state_name %in% states_u, !(county_name %in% states_u)) %>% select(4:6, 11:43)
#get geographic info
county_area <- read.csv("../small-datasets/county-area-2010.csv", header=TRUE, skip=1) %>% select(6:7,10:12)
#clean county_name
county_pop <- mutate(county_pop, county_name = str_remove(county_name, "County") %>% str_trim(side="both") %>% str_to_lower())
#tidy populations
county_pop <- county_pop %>%
gather(key="year", value="population", -c("areaname", "state_name", "county_name")) %>%
mutate(year = str_remove(year, "pop") %>% as.numeric())
#tidy areas
names(county_area) <- c("state_name", "county_name", "total_area", "water_area", "land_area")
county_area <- county_area %>%
mutate(state_name = str_split(state_name, "-", n=3, simplify = TRUE)[,2] %>%
str_trim(side="both")) %>% filter(state_name %in% states_u, !(county_name %in% states_u)) %>%
mutate(county_name = str_remove(county_name, "County") %>% str_trim(side = "both") %>% str_to_lower())
#join
county_data <- inner_join(county_pop, county_area, by=c("state_name", "county_name"))
county_data <- county_data %>%
mutate(pop_land_density = population/land_area)
all_data <- inner_join(western_map, county_data, by=c("subregion"="county_name"))
plot_ly(all_data, x=~long, y=~lat, color=~population, frame=~year) %>%group_by(group) %>% add_polygons()
plot_ly(all_data, x=~long, y=~lat, fill=~population, frame=~year) %>%group_by(group) %>% add_polygons()
blank_layer <- list(
title = "",
showgrid = F,
showticklabels = F,
zeroline = F)
all_data %>%
plotly::group_by(group) %>%
plot_ly( x = ~long,
y = ~lat,
fillcolor = ~population,
hoverinfo = ~areaname,
frame = ~year) %>%
add_polygons(
line = list(color = 'black', width = 0.5)) %>%
layout(
xaxis = blank_layer,
yaxis = blank_layer)
all_data %>%
plotly::group_by(group) %>%
plot_ly( x = ~long,
y = ~lat,
fillcolor = ~population,
hoverinfo = ~areaname) %>%
add_polygons(
line = list(color = 'black', width = 0.5)) %>%
layout(
xaxis = blank_layer,
yaxis = blank_layer)
all_data %>%
plotly::group_by(group) %>%
plot_ly( x = ~long,
y = ~lat,
fillcolor = 'white',
hoverinfo = "text",
text=~paste(areaname,", ",state_name) )%>%
add_polygons(
line = list(color = 'black', width = 0.5)) %>%
layout(
xaxis = blank_layer,
yaxis = blank_layer)
all_data %>% group_by(group) %>%
plot_ly(x = ~long, y = ~lat, color = ~population,
text = ~subregion, hoverinfo = 'text') %>%
add_polygons(line = list(width = 0.4)) %>%
add_polygons(
fillcolor = 'transparent',
line = list(color = 'black', width = 0.5),
showlegend = FALSE, hoverinfo = 'none'
) %>%
layout(
title = "California Population by County",
titlefont = list(size = 10),
xaxis = list(title = "", showgrid = FALSE,
zeroline = FALSE, showticklabels = FALSE),
yaxis = list(title = "", showgrid = FALSE,
zeroline = FALSE, showticklabels = FALSE)
)
library(purrr)
map(county_area, ~mean(.x))
map(county_area, ~if(is.numeric(.x){mean(.x)})
map(county_area, ~if(is.numeric(.x)mean(.x))
map(county_area, ~if(is.numeric(.x)){mean(.x)})
map(county_area[,3:5], ~mean(.x))
map(county_area[,3:5], ~sd(.x))
map(county_area[,3:5], ~sd(.x)) -> areasd
areasd$total_area
map_dbl(county_area[,3:5], ~sd(.x)) -> areasd
areasd
install.packages("transformr")
df <- read.csv("https://raw.githubusercontent.com/bcdunbar/datasets/master/californiaPopulation.csv")
cali <- map_data("county") %>%
filter(region == 'california')
pop <- df %>%
group_by(County.Name) %>%
summarise(Pop = sum(Population))
pop$County.Name <- tolower(pop$County.Name) # matching string
cali_pop <- merge(cali, pop, by.x = "subregion", by.y = "County.Name")
cali_pop$pop_cat <- cut(cali_pop$Pop, breaks = c(seq(0, 11000000, by = 500000)), labels=1:22)
p <- cali_pop %>%
group_by(group) %>%
plot_ly(x = ~long, y = ~lat, color = ~pop_cat, colors = c('#ffeda0','#f03b20'),
text = ~subregion, hoverinfo = 'text') %>%
add_polygons(line = list(width = 0.4)) %>%
add_polygons(
fillcolor = 'transparent',
line = list(color = 'black', width = 0.5),
showlegend = FALSE, hoverinfo = 'none'
) %>%
layout(
title = "California Population by County",
titlefont = list(size = 10),
xaxis = list(title = "", showgrid = FALSE,
zeroline = FALSE, showticklabels = FALSE),
yaxis = list(title = "", showgrid = FALSE,
zeroline = FALSE, showticklabels = FALSE)
)
devtools::install_github("jennybc/repurrrsive")
devtools::install_github("jennybc/repurrrsive")
devtools::install_github("jennybc/repurrrsive")
devtools::install_github("thomasp85/patchwork")
library(purrr)
library(dplyr)
library(repurrrsive)
map_chw(sw_planets, "name")
map_chr(sw_planets, "name")
sw_planets
map_chr(sw_planets, "name") %>% set_names(map_chr(sw_planets, "url"))
head(mtcars)
map2(mtcars, mtcars, ~lm(.y~.x))
map(mtcars[,2:11], ~lm(mtcars$mpg~.x))
map_dbl(mtcars, mean)
map_dbl(mtcars, ~mean)
map_dbl(mtcars, ~mean(.x))
map_dbl(mtcars, ~(.x-mean(.x))
)
map(1:10, runif)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(plotly)
gap <- read.csv("../small-datasets/gapminder-tidy.csv", header=TRUE)
gap <- read.csv("../small-datasets/gapminder_tidy.csv", header=TRUE)
gap %>% plot_ly(x=~life, y=~gdp) %>% add_markers()
gap %>% plot_ly(x=~life, y=~gdp, color = ~region) %>% add_markers()
count(gap, region)
View(gap)
head(gap)
?add_markers
map_data('world', region="africa") %>% head()
map_data('world') %>% head()
map_data('africa') %>% head()
map_data('states') %>% head()
head(gap)
?volcano
db <- read.csv("~/Downloads/2019-01-30T1445_Grades-CSC-270-01.csv", header=TRUE)
head(db)
library(dplyr)
db <- select(db, email=SIS.Login.ID)
head(db)
write.csv(db[2:nrow(db),], "~/Downloads/csc270-email.csv", row.names = FALSE)
dm <- read.csv("~/Downloads/2019-01-30T1516_Grades-MAT-252-01.csv", header=TRUE)
dm <- select(dm, email=SIS.Login.ID)
write.csv(dm, "~/Downloads/dm-email.csv", row.names = FALSE)
more dm
head(dm)
cs <- read.csv("~/Downloads/2019-01-30T1516_Grades-CSC-150-02.csv", header=TRUE)
cs <- read.csv("~/Downloads/2019-01-30T1508_Grades-CSC-150-02.csv", header=TRUE)
cs <- select(cs, email=SIS.Login.ID)
write.csv(cs, "~/Downloads/cs-email.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(maps)
m <- map("us", regions="states")
m <- map("usa", regions="states")
m <- map("usa")
m
m <- map("states")
m <- map("state")
fortify(m)
m
ggplot(m, aes(x=x, y=y))+geom_polygon()
ggplot(as.dataframe(m), aes(x=x, y=y))+geom_polygon()
ggplot(data.frame(m), aes(x=x, y=y))+geom_polygon()
maps::us.cities
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA"))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Truckee CA", "Harrisonburg VA"))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "South Lake Tahoe CA", "Harrisonburg VA", "Charlotte NC"))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "South Lake Tahoe NV", "Harrisonburg VA", "Charlotte NC"))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC"))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC")) -> city
m+ggplot(city, aes(x=long, y=lat, size=pop))+geom_point()
m <- map_data('state')
ggplot()+geom_polygon(m, aes(x=long, y-lat, group=group), color="black")+geom_point(city, aes(x=long, y=lat, size=pop))
ggplot()+geom_polygon(m, mapping=aes(x=long, y-lat, group=group), color="black")+geom_point(city, mapping=aes(x=long, y=lat, size=pop))
ggplot()+geom_polygon(m, mapping=aes(x=long, y=lat, group=group), color="black")+geom_point(city, mapping=aes(x=long, y=lat, size=pop))
ggplot()+geom_polygon(m, mapping=aes(x=long, y=lat, group=group), color="black",fill='white')+geom_point(city, mapping=aes(x=long, y=lat, size=pop))
filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC", "Seattle WA")) -> city
names(city)
cities <- filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC", "Seattle WA"))
cities <- rbind.data.frame(cities, data.frame(name="Truckee CA", country.etc="CA", pop=16533, lat=39.3280, long=120.1833, capital=0))
View(cities)
ctime <- read.csv("~/github-web/jpreszler/static/files/city-time.csv", header=TRUE)
View(ctime)
ctotal <- ctime %>% group_by(name) %>% summarise(years=sum(years)) %>% ungroup()
cities <- inner_join(cities, ctotal, by="name")
ggplot()+geom_polygon(states, mapping=aes(x=long, y=lat), color="black", fill="white")+geom_point(cities, mapping = aes(x=long, y=lat, size=years), alpha=.3)+coord_map()
states <- map_data("state")
cities <- filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC", "Seattle WA"))
#glue on Truckee, not in us.cities data
cities <- rbind.data.frame(cities, data.frame(name="Truckee CA", country.etc="CA", pop=16533, lat=39.3280, long=120.1833, capital=0))
ctime <- read.csv("~/github-web/jpreszler/static/files/city-time.csv", header=TRUE)
ctotal <- ctime %>% group_by(name) %>% summarise(years=sum(years)) %>% ungroup()
cities <- inner_join(cities, ctotal, by="name")
ggplot()+geom_polygon(states, mapping=aes(x=long, y=lat), color="black", fill="white")+geom_point(cities, mapping = aes(x=long, y=lat, size=years), alpha=.3)+coord_map()
states <- map_data("state")
cities <- filter(maps::us.cities, name %in% c("Reno NV", "Sacramento CA", "Salt Lake City UT", "Tacoma WA", "Boise ID", "Tulare CA", "Harrisonburg VA", "Charlotte NC", "Seattle WA"))
#glue on Truckee, not in us.cities data
cities <- rbind.data.frame(cities, data.frame(name="Truckee CA", country.etc="CA", pop=16533, lat=39.3280, long=-120.1833, capital=0))
ctime <- read.csv("~/github-web/jpreszler/static/files/city-time.csv", header=TRUE)
ctotal <- ctime %>% group_by(name) %>% summarise(years=sum(years)) %>% ungroup()
cities <- inner_join(cities, ctotal, by="name")
ggplot()+geom_polygon(states, mapping=aes(x=long, y=lat), color="black", fill="white")+geom_point(cities, mapping = aes(x=long, y=lat, size=years), alpha=.3)+coord_map()
ggplot()+geom_polygon(states, mapping=aes(x=long, y=lat, group=group), color="black", fill="white")+geom_point(cities, mapping = aes(x=long, y=lat, size=years), alpha=.3)+coord_map()
View(ctime)
View(cities)
ggplot()+geom_polygon(states, mapping=aes(x=long, y=lat, group=group), color="black", fill="white")+geom_point(cities, mapping = aes(x=long, y=lat, size=years, color=name), alpha=.3)+coord_map()
load("~/gitlab/math-placement/data/m101-model-ready.csv")
m101.model.ready <- read.csv("~/gitlab/math-placement/data/m101-model-ready.csv", stringsAsFactors=FALSE)
View(m101.model.ready)
m125.model.ready <- read.csv("~/gitlab/math-placement/data/m125-model-ready.csv", stringsAsFactors=FALSE)
View(m125.model.ready)
library(dplyr)
m101 <- select(m101.model.ready, -c(X.1, LastName, FirstName))
m125 <- select(m125.model.ready, -c(X.1, LastName, FirstName))
library(digest)
md5(m101$email)
library(openssl)
md5(m101$email)
m101$email <- md5(m101$email)
m125$email <- md5(m125$email)
write.csv(m101, file="~/github-web/insight/m101-model-ready-anon.csv", row.names = FALSE)
write.csv(m125, file="~/github-web/insight/m125-model-ready-anon.csv", row.names = FALSE)
View(m101)
install.packages("kableExtra")
install.packages("glmnet")
setwd("/home/jpreszler/github-web/jpreszler/")
blogdown::serve_site()
