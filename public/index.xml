<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jason I. Preszler on Jason I. Preszler</title>
    <link>/</link>
    <description>Recent content in Jason I. Preszler on Jason I. Preszler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Jason Preszler</copyright>
    <lastBuildDate>Thu, 28 Dec 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Thoughts on Severe Class Imbalance </title>
      <link>/post/2018-01-01/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-01/</guid>
      <description>&lt;p&gt;Besides lots of family time and the creation of this blog/website, this is what I’ve been thinking about over the winter break.&lt;/p&gt;
&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;As part of my research in &lt;em&gt;emergent reducibility&lt;/em&gt;, I’ve had to face a binary classification situation with severe class imbalance. Among brute-force searches, it seems that there’s roughly 1 case of emergent reducibility (what I’m looking for) for every 1 million irreducible cubic polynomials. It is known that there are infinitely many cubic polynomials with emergent reducibility.&lt;/p&gt;
&lt;p&gt;One standard way of dealing with class imbalance is to artificially increase the incidence of positive cases in the training data, but I’ve seen very little about how to decide how much to adjust the ratio of the two classes - that’s what this post is about.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;training-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Training Data&lt;/h1&gt;
&lt;p&gt;To examine the relationship of class imbalance on several classifiers, I build 21 training sets each with the same 52 cases of emergent reducibility and between 500 and 2500 (by 100 increments) polynomials without emergent reducibility. Each training set was used to train a variety of logristic regression, random forest, naive Bayes, and k-nearest neighbor models via caret.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;confusion-matrices&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Confusion Matrices&lt;/h1&gt;
&lt;p&gt;Once the models were trained, they were all tested against the same data set with 23 cases of emergent reducibility (no overlap with training data) and 8000 cases without emergent reducibility. For each model and training set combination, a confusion “matrix” was build, this is in the file &lt;a href=&#34;../../static.post/confMats.csv&#34;&gt;confMats.csv&lt;/a&gt;. Let’s read that into R and add another variable, &lt;em&gt;mdlType&lt;/em&gt; that’s either &lt;em&gt;logistic&lt;/em&gt;, &lt;em&gt;RF&lt;/em&gt;, or &lt;em&gt;other&lt;/em&gt;. This is to facet some graphs later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;confMats &amp;lt;- read.csv(&amp;quot;../../static/post/confMats.csv&amp;quot;, header=TRUE)

logLocations &amp;lt;- grep(&amp;quot;lr&amp;quot;, confMats$mdl)
rfLocations &amp;lt;- grep(&amp;quot;rf&amp;quot;, confMats$mdl)

confMats$mdlType &amp;lt;- vector(mode=&amp;quot;character&amp;quot;, length=length(confMats$mdl))

confMats[logLocations,]$mdlType &amp;lt;- &amp;quot;Logistic&amp;quot;
confMats[rfLocations,]$mdlType &amp;lt;- &amp;quot;RF&amp;quot;
confMats[!(1:length(confMats$mdl) %in% c(logLocations,rfLocations)),]$mdlType&amp;lt;-&amp;quot;Other&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;roc-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ROC Plots&lt;/h1&gt;
&lt;p&gt;Now we’ll plot our confusion matrices in ROC space. First, Figure &lt;a href=&#34;#fig:scatter&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

#11 distinct colors, courtesy of colorbrewer2.org
cb11&amp;lt;-c(&amp;#39;#a6cee3&amp;#39;,&amp;#39;#1f78b4&amp;#39;,&amp;#39;#b2df8a&amp;#39;,&amp;#39;#33a02c&amp;#39;,&amp;#39;#fb9a99&amp;#39;,&amp;#39;#e31a1c&amp;#39;,&amp;#39;#fdbf6f&amp;#39;,&amp;#39;#ff7f00&amp;#39;,&amp;#39;#cab2d6&amp;#39;,&amp;#39;#6a3d9a&amp;#39;,&amp;#39;#ffff99&amp;#39;)
ggplot(confMats,aes(x=FP/(FP+TN),y=TP/(TP+FN),col=mdl))+geom_point()+facet_wrap(~mdlType)+scale_color_manual(values=cb11)+ggtitle(&amp;quot;ROC Plots of Models and Class Imbalance &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:scatter&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2018-01-01_files/figure-html/scatter-1.png&#34; alt=&#34;A Scatterplot.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A Scatterplot.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The model &lt;em&gt;max&lt;/em&gt; seems to find the most, but this simply marks a polynomial as having emergent reducibility if any other model says it does. This indicates some models find cases that others miss (I have some nice heatmaps showing this also, for another day). The logistic regression models have much more irregular variation than I was expecting.&lt;/p&gt;
&lt;p&gt;To see how varying the number of non-emergent reducibile polynomials impacts performs, I’ll throw in some animation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

pathPlot &amp;lt;- ggplot(confMats,aes(x=FP/(FP+TN),y=TP/(TP+FN),col=mdl,frame=ner))+geom_path(aes(cumulative=TRUE, group=mdl))+facet_wrap(~mdlType)+scale_color_manual(values=cb11)+ggtitle(&amp;quot;Animated ROC Paths&amp;quot;)

gganimate(pathPlot)&lt;/code&gt;&lt;/pre&gt;
&lt;video width=&#34;672&#34;  controls loop&gt;
&lt;source src=&#34;/post/2018-01-01_files/figure-html/aniPath.webm&#34; /&gt;
&lt;/video&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Emergent Reducibility</title>
      <link>/project/emergent-reducibility/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/project/emergent-reducibility/</guid>
      <description>&lt;p&gt;Project details&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistics: Side B</title>
      <link>/talk/stat-b/</link>
      <pubDate>Sun, 22 Oct 2017 00:00:00 -0600</pubDate>
      
      <guid>/talk/stat-b/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Infinite Family of Cubic Polynomials with Depth 1 Emergent Reducibility</title>
      <link>/talk/jmm-2015/</link>
      <pubDate>Sun, 11 Jan 2015 00:00:00 -0700</pubDate>
      
      <guid>/talk/jmm-2015/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Infinite Family of Cubics with Emergent Reducibility at Depth 1</title>
      <link>/publication/infinite-cubics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/publication/infinite-cubics/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
