<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Jason I. Preszler</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Jason I. Preszler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Jason Preszler</copyright>
    <lastBuildDate>Mon, 18 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Mapping with an 800 Pound Gorilla</title>
      <link>/post/2019-03-18-matplotlib-map/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-03-18-matplotlib-map/</guid>
      <description>I’ve been focusing on python recently to become a bi-lingual data scientist. Probably my least favorite thing about python is its plotting libraries - there are too many options built on top of matplotlib which pre-dates pandas dataframes. This makes for some clunky code and blurry boundaries (both “is that a seaborn, pandas, or matplotlib function?” and situations with 3 equally messy solutions but in very different ways). In my opinion, ggplot2’s deep interplay with dataframes makes a lot more sense and ggplot’s layers make it easy to change plot type (just switch the geom_), add facets, and tweak aesthetics.</description>
    </item>
    
    <item>
      <title>Expectation-Maximization</title>
      <link>/post/2019-02-23-em-1/</link>
      <pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-02-23-em-1/</guid>
      <description>As part of some clustering work and learning about hidden Markov models, I’ve been doing some reading about the EM algorithm and it’s applications. It’s a pretty neat algorithm (I love iterative algorithms like Newton’s method and the Euclidean algorithm) so I thought I’d illustrate how it works.
I’ve also been doing a bit more python recently, so I thought I would do all this in python rather than R.</description>
    </item>
    
    <item>
      <title>Reticulated Mixture Models</title>
      <link>/post/2018-11-10-reticulate-mm/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-10-reticulate-mm/</guid>
      <description>Clearly, there’s no such thing as a “reticulated mixture model” but if you create one I’ll gladly take credit for the name. Instead this post is a demonstration of using mixture models for clustering and the interplay of R and Python via RStudio’s reticulate package.
Mixture Model Basics The idea behind mixture models is that you have data containing information from two (or more) subgroups and you want to uncover structure of the subgroups.</description>
    </item>
    
  </channel>
</rss>