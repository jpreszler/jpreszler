<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Jason I. Preszler</title>
    <link>/tags/r/</link>
    <description>Recent content in R on Jason I. Preszler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Jason Preszler</copyright>
    <lastBuildDate>Fri, 11 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tidy Clouds</title>
      <link>/post/2019-01-11-wc/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-01-11-wc/</guid>
      <description>In my data visualization class I had the students get a book from Project Gutenberg using the gutenbergr package and build a word cloud using tidytext and wordcloud. It’s much easier that the “old” corpus/text mapping approach, and when the students were sharing their clouds they started showing the cloud and having students try to guess the book. This made me think of using a Shiny runtime to make a little word cloud guessing game.</description>
    </item>
    
    <item>
      <title>Sankey Diagram</title>
      <link>/post/2018-12-27-sankey/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-12-27-sankey/</guid>
      <description>Update 7/23/2019 Various package updates have created problems with showing more than one javascript plot on a post. I’ve added calls to htlwidgets::onRender to get at least one plot displayed. I may revisit this, but the interaction between hugo, blogdown, and various javascript libraries (chorddiag, networkD3, D3, data tables, etc) is more than I’m able to dive into at the moment.
This post is about a type of visualization the will hopefully help see how students “flow” through college.</description>
    </item>
    
    <item>
      <title>PCA Overview</title>
      <link>/post/2018-11-24-pca/</link>
      <pubDate>Sat, 24 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-24-pca/</guid>
      <description>This post is primarily to give the basic overview of principal components analysis (PCA) for dimensionality reduction and regression. I wanted to create it as a guide for my regression students who may find it useful for their projects. First, let’s note the two main times that you may want to use PCA - dimensionality reduction (reducing variables in a dataset) and removing colinearity issues. These are not exclusive problems, often you want to do both.</description>
    </item>
    
    <item>
      <title>Reticulated Mixture Models</title>
      <link>/post/2018-11-10-reticulate-mm/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-10-reticulate-mm/</guid>
      <description>Clearly, there’s no such thing as a “reticulated mixture model” but if you create one I’ll gladly take credit for the name. Instead this post is a demonstration of using mixture models for clustering and the interplay of R and Python via RStudio’s reticulate package.
Mixture Model Basics The idea behind mixture models is that you have data containing information from two (or more) subgroups and you want to uncover structure of the subgroups.</description>
    </item>
    
    <item>
      <title>Ridges of Normality</title>
      <link>/post/2018-10-01-norm-ridge/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-10-01-norm-ridge/</guid>
      <description>One of the classic assumptions of the linear regression models is that, conditioned on the explanatory variables, the response variable should be normally distributed. While teaching this the other day, I had a flash of insight into how to visualize this - ridge-line plots!
Data I’ve been using Matloff’s Statistical Regression and Classification book, which uses the mlb dataset from his freqparcoord package. This has data on heights, weights, ages, positions, and teams of over 1000 major league baseball players.</description>
    </item>
    
    <item>
      <title>What a Tangled Web We Weave...</title>
      <link>/post/2018-08-21-chords/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-08-21-chords/</guid>
      <description>Update 7/23/2019 Various package updates have created problems with showing more than one javascript plot on a post. I’ve added calls to htlwidgets::onRender to get at least one plot displayed. I may revisit this, but the interaction between hugo, blogdown, and various javascript libraries (chorddiag, networkD3, D3, data tables, etc) is more than I’m able to dive into at the moment.
cd &amp;lt;- chorddiag( xtabs(~MAJOR+minor, data = mmhl[mmhl$Grad.</description>
    </item>
    
    <item>
      <title>Lesser Known Verbs: top_n</title>
      <link>/post/2018-07-30-top_n/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-07-30-top_n/</guid>
      <description>I’ve been using R since 2006. That predates RStudio and the tidyverse. I remember the struggle of keeping track of the variants of apply and often fiddling with them to get code to work.
Then came plyr and the dplyr and my life has never been the same. The major verbs of dplyr include select, filter, mutate, group_by, summarise, and arrange; and if you are doing data analysis in R then you should be fluent in them.</description>
    </item>
    
    <item>
      <title>Re-Counting Classes</title>
      <link>/post/2018-07-24-recount-class/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-07-24-recount-class/</guid>
      <description>Edit 7/27/2018 I realized that MFL’s name change to WLC didn’t change the prefix of their courses, this broke my scrapper. Below is an updated post that deals with this.
Back in early May, I wrote a post about scraping the College of Idaho catalog: Counting Classes. Below if the same post (boring…) except that the “current catalog” has been updated. This is really a demonstration of reproducibility, the upstream data has changed and ideally all my code still works.</description>
    </item>
    
    <item>
      <title>DT: When Tables are the Product</title>
      <link>/post/2018-06-28-dt/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-06-28-dt/</guid>
      <description>In RMarkdown documents I often have a need to display tables, which I usually try to keep small with only the most useful information displayed. However, a recent project made me look for a better way to share tabular data with non-data-scientists. The answer was R’s DT package, which allows for very powerful displays of tabular data.
Today’s data will be a summary of enrollment data from the College of Idaho:</description>
    </item>
    
    <item>
      <title>Maps Majors in Neo4J</title>
      <link>/post/2018-06-18-neo4j-majors/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-06-18-neo4j-majors/</guid>
      <description>UPDATE (6/20/2018) The cypher query for Table 3 only used components with “optional” courses so the capstone and topics compnents of the Math/CS major weren’t included in table 3.
UPDATE (6/19/2018) The original version of this post used incorrectly loaded data that caused to “Core” of every major to have the same classes attached to it. This was noticed by my colleague Dave Rosoff and has been corrected.</description>
    </item>
    
    <item>
      <title>Maps Minors in Neo4J</title>
      <link>/post/2018-06-16-neo4j-demo/</link>
      <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-06-16-neo4j-demo/</guid>
      <description>A college curriculum seems like something that is a natural fit for a graph database. My last post collected data from the College of Idaho’s online catalog, using that and some information about majors and minors I’ve populated a graph database in Neo4j. In this post I’ll show how to do some basic queries that return tabular data as well as graph data using .
Graph DB Basics For those who haven’t had much discrete math or computer science, a graph is a collection of nodes (aka vertices) and edges that connect nodes.</description>
    </item>
    
    <item>
      <title>Counting Classes: The Basics</title>
      <link>/post/2018-05-05-counting-class/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-05-05-counting-class/</guid>
      <description>At the College of Idaho, there’s been discussion about visualizing the curriculum as well as understanding the curriculum. Naturally this interests me as a chance to wallow in some complicated data (students are required to complete a major and 3 minors across 4 “peaks” rather than complete courses from a traditional “core”). I thought using R and a Neo4j graph database would be useful (something to look forward to) - but first I needed to get data from the catalogue!</description>
    </item>
    
    <item>
      <title>SQL in RMarkdown!</title>
      <link>/post/2018-04-01-sql-rmd/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-04-01-sql-rmd/</guid>
      <description>This semester I’m teaching Applied Databases for the first time and have been struggling with some notes and handouts for students; as well as simple, easy to use database interfaces that work well across platforms. I love RMarkdown, and today realized that knitr has an SQL code engine!
Basic Syntax I often give handouts on SQL statements as we learn about them, so I need a nice way to show commands.</description>
    </item>
    
    <item>
      <title>Running Tacoma: Maps</title>
      <link>/post/2018-3-11-run-tacoma1/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-3-11-run-tacoma1/</guid>
      <description>When I lived in Tacoma, I was running quite a bit. Since I moved away my training has become much more irregular, but I thought it would be interesting to take the Tacoma data from my current Garmin Forerunner 220 a take a look.
Data Prep The Garmin stores data in .fit format, but gpsbabel can translate to a nicely structured GPX file, which is what I’ll start with here.</description>
    </item>
    
    <item>
      <title>Idaho ACS Mapping</title>
      <link>/post/2018-01-27-acs-map/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-27-acs-map/</guid>
      <description>Recently some diversity stats have been circulated around the College of Idaho, and as new Idahoan I wondered about the general diversity (or lack thereof) in Idaho. I remembered seeing this post a while back about mapping in R, so I went to work.
Shapefiles First, we need shapefiles for both the Idaho country boundaries and census tracts, which will give finer detail for data. These can be downloaded from the [US Census Bureau] (https://www.</description>
    </item>
    
    <item>
      <title>Stock Random Walks</title>
      <link>/post/2018-01-15-stock-rw/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-15-stock-rw/</guid>
      <description>Introduction Recently a student in another course came to my office looking for someone “who could explain the Monte Carlo simulation” to her. I was caught a bit off-guard since (a) it was 10 minutes before my geometry class and (b) there is no single Monte Carlo simulation.
After a brief discussion, I found out she wanted to predict stock prices using Monte Carlo simulation, but she thought that the Monte Carlo simulation provided the prediction - she couldn’t say how the actual predictions were being made which is the crucial part.</description>
    </item>
    
    <item>
      <title>Thoughts on Severe Class Imbalance </title>
      <link>/post/2018-01-01/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-01/</guid>
      <description>Besides lots of family time and the creation of this blog/website, this is what I’ve been thinking about over the winter break.
Background As part of my research in emergent reducibility, I’ve had to face a binary classification situation with severe class imbalance. Among brute-force searches, it seems that there’s roughly 1 case of emergent reducibility (what I’m looking for) for every 1 million irreducible cubic polynomials. It is known that there are infinitely many cubic polynomials with emergent reducibility.</description>
    </item>
    
  </channel>
</rss>