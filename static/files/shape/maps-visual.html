---
title: "Visualizing Classifier Performance"
author: "Jason Preszler"
date: "March 1, 2018"
output: 
  ioslides_presentation:
    incremental: true
    widescreen: true
    logo: CofI-vert.png
  
---



<style>
h2 {
  color:white;
  background:rgb(90,33,73);
}

.gdbar img {
  width: 125px !important;
  height: 125px !important;
  margin: 3px 3px;
}

.gdbar {
  width: 140px !important;
  height: 140px !important;
}

slides > slide:not(.nobackground):before {
  width: 80px;
  height: 80px;
  background-size: 80px 80px;
}
slides > slide.backdrop {
  background: white;
}
slides > slide.dark {
  background: white !important;
}
.title-slide hgroup h1 {
  font-size: 70px;
  line-height: 1.4;
  letter-spacing: -3px;
  color: rgb(90,33,73);
}
/* effects title */
.title-slide hgroup h2 {
  font-size: 55px;
  color: rgb(90,30,73);
  font-weight: inherit;
}
slides > slide {
  display: none;
  font-family: 'Open Sans', Arial, sans-serif;
  font-size: 26px;
  color: #231f20;
  width: 900px;
  height: 700px;
  margin-left: -450px;
  margin-top: -350px;
  padding: 40px 60px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  -ms-border-radius: 5px;
  -o-border-radius: 5px;
  border-radius: 5px;
  -webkit-transition: all 0.6s ease-in-out;
  -moz-transition: all 0.6s ease-in-out;
  -o-transition: all 0.6s ease-in-out;
  transition: all 0.6s ease-in-out;
}

/* effects author/date on title slide */
.title-slide hgroup p {
  font-size: 30px;
  color: black;
  line-height: 1.3;
  margin-top: 2em;
}
.footer {
    color: black;
    background: #E8E8E8;
    position: fixed;
    top: 90%;
    text-align:center;
    width:100%;
}
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}
.small-code pre code {
  font-size: 1em;
}

.reveal h3 {
  word-wrap: normal;
  -moz-hyphens: none;
}
.reveal h1 {
  word-wrap: normal;
  -moz-hyphens: none;
}
</style>
<div id="goals" class="section level2">
<h2>Goals</h2>
<ul>
<li>Foster interest in CS 285, MAT 470, and Data Science Minor (all new)</li>
<li>Demonstrate machine learning and data visualization techniques</li>
<li><p>Share some of what I’m interested in</p>
<p>-Slides will be available on <a href="http://jpreszler.rbind.io" class="uri">http://jpreszler.rbind.io</a></p></li>
</ul>
</div>
<div id="background-classification-and-class-imbalance" class="section level1">
<h1>Background: <br>Classification and Class Imbalance</h1>
<div id="classification" class="section level2">
<h2>Classification</h2>
<ul>
<li>Classification problems predict which category an item belongs to.</li>
<li><p>Examples:</p>
<ul>
<li><em>Is email spam?</em></li>
<li><em>Which of 5 people wrote this paper?</em></li>
<li><em>Is this transaction fraudulent?</em></li>
</ul></li>
<li><p>This is one of the pillars of machine learning.</p></li>
</ul>
</div>
<div id="class-imbalance" class="section level2">
<h2>Class Imbalance</h2>
<ul>
<li><p>When distribution of categories is highly skewed, <br> we have <strong>class imbalance</strong></p></li>
<li><p>This makes classification harder.</p></li>
<li><p>Our problem: <em>given data on irreducible cubic polynomial <span class="math inline">\(f(x)\)</span>, will <span class="math inline">\(f\circ f(x)\)</span> be irreducible?</em></p></li>
<li><p>Data: over <span class="math inline">\(200\)</span> million irreducible cubics, <span class="math inline">\(75\)</span> have reducible iterates.</p></li>
</ul>
</div>
</div>
<div id="machine-learning-process" class="section level1">
<h1>Machine Learning Process</h1>
<div id="machine-learning-workflow" class="section level2">
<h2>Machine Learning Workflow</h2>
<ul>
<li>Get data: C with FLiNT and OpenMP to build data set.</li>
<li>Build Training Set (typically <span class="math inline">\(60\% - 80\%\)</span> of data)</li>
<li><p>Build Test Set (the rest of data)</p></li>
<li><p>Use training set to build model(s), measure performance using test set.</p></li>
</ul>
</div>
<div id="typical-imbalance-solution" class="section level2">
<h2>Typical Imbalance Solution</h2>
<ul>
<li>Rebalance by inflating rate of low-class cases in training set.</li>
<li>Keep test set class distribution similar to real-world.</li>
<li>But how much should we adjust class distributions by?</li>
</ul>
</div>
</div>
<div id="my-process" class="section level1">
<h1>My Process</h1>
<!--## Obstacles

- R works purely "in memory" 
- Great for small data sets
- Very problematic for moderately sized datasets
- Full dataset: 11GB
- Solution: data.table

- Lots of data "wrangling"
-->
<div id="build-sets" class="section level2">
<h2>Build Sets</h2>
<ul>
<li>Read data in with data.table</li>
<li>Remove duplicates</li>
<li>Build 21 training sets</li>
<li>Each has same 52 ER cases</li>
<li>Number of non-ER varies from 500 to 2500 by 100</li>
<li>Non-ER cases are sampled from main dataset</li>
<li>One test set, 23 ER cases and 8000 non-ER</li>
</ul>
</div>
<div id="build-ner-r-code" class="section level2">
<h2>Build NER R code</h2>
<p>mkNER.R:</p>
<pre class="r"><code>  bigNER &lt;- fread(bigFile, header=TRUE, sep=&quot;,&quot;)
  bigNER &lt;- bigNER[!duplicated(bigNER) &amp; bigNER$numFact==1,]

    samps &lt;- sapply(nerSize, function(x) sample(1:n, x, 
                                            replace = FALSE))
    nerss &lt;- map(samps, function(x) bigNER[x,])
    for(i in 1:length(nerSize)){
      trsName &lt;- paste(paste(&quot;NERtrain&quot;,nerSize[i],
                             sep = &quot;-&quot;),&quot;csv&quot;,sep=&quot;.&quot;)
      write.csv(nerss[[i]],trsName, row.names = FALSE)
    }</code></pre>
</div>
<div id="building-training-sets" class="section level2">
<h2>Building Training Sets</h2>
<pre class="r"><code>  erIDX &lt;- sample(1:length(er$cube), .7*length(er$cube), replace=FALSE)
  for(i in nerTrainFiles){
    ner &lt;- loadTT(i)
    ner &lt;- separate(ner, poly,
              into=c(&quot;len&quot;,&quot;const&quot;,&quot;lin&quot;,&quot;quad&quot;,&quot;cube&quot;), 
                sep=&quot;[[ ]]+&quot;) %&gt;% dplyr::select(c(-len,-content))
    tr &lt;- rbind.data.frame(ner, er[erIDX,])
    write.csv(tr, paste(paste(&quot;train&quot;, length(ner$cube),
                    sep=&quot;-&quot;), &quot;csv&quot;,sep=&quot;.&quot;),row.names=FALSE)
    rm(ner)
    rm(tr)
  }</code></pre>
</div>
<div id="model-building" class="section level2">
<h2>Model Building</h2>
<p>For each of the 21 training sets, we’ll build 9 models</p>
<ul>
<li>3 logistic regression with <strong>regularization</strong> (glmnet)</li>
<li>4 random forests</li>
<li>naive bayes, knn</li>
<li><p>That’s 189 models!</p></li>
<li><p>Each model build using 10-fold cross validation and “Kappa” error metric</p></li>
<li><p>Need Parallelization to train multiple models at once, and multiple CV runs</p></li>
</ul>
</div>
<div id="cv-and-kappa" class="section level2">
<h2>CV and Kappa</h2>
<ul>
<li><p>Cross-validation:</p>
<ul>
<li><p>split training set into mini-training/test set pairs</p></li>
<li><p>build model and check model on mini-sets with different hyperparameter values</p></li>
<li><p>build model on full training set using hyperparameters with “best” error metric</p></li>
</ul></li>
<li><p>Kappa:</p>
<ul>
<li><p>Standard error metric for imbalanced classifiers</p></li>
<li><p>Compares observed accuracy with what’s expected from random chance.</p></li>
</ul></li>
</ul>
</div>
<div id="model-building-code" class="section level2">
<h2>Model Building Code</h2>
<p>One of the models:</p>
<pre class="r"><code>library(caret)
library(doParallel)
  cl &lt;- makeCluster(detectCores())
  registerDoParallel(cl)
  
 tr1.rfs &lt;- train(numFact~const+lin+quad+cube+nSign+pSign+sigReal,
                  data=trs1, method=&quot;rf&quot;, metric = &quot;Kappa&quot;,  
                  trControl = trainControl(method=&quot;cv&quot;, 
                              number = 10, allowParallel = TRUE))

 tst$rfs &lt;- predict(tr1.rfs, tst, type = &quot;prob&quot;)[,2]

  stopCluster(cl)</code></pre>
</div>
</div>
<div id="model-performance" class="section level1">
<h1>Model Performance</h1>
<div id="confusion-matrices" class="section level2">
<h2>Confusion Matrices</h2>
<table>
<thead>
<tr class="header">
<th align="center">Predicted vs. Actual</th>
<th align="center">Act. 1</th>
<th align="center">Act. 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Pred. 1</td>
<td align="center">TN</td>
<td align="center">FN</td>
</tr>
<tr class="even">
<td align="center">Pred. 2</td>
<td align="center">FP</td>
<td align="center">TP</td>
</tr>
</tbody>
</table>
<ul>
<li>Assign prediction class from probabilities <span class="math inline">\(p\)</span> of having 2 factors by checking <span class="math inline">\(p \ge \theta\)</span>.</li>
</ul>
</div>
<div id="confusion-data-frame" class="section level2">
<h2>Confusion Data Frame</h2>
<p>Sample of Data Frame with 1134 confusion matrices!</p>
<table>
<thead>
<tr class="header">
<th align="left">mdl</th>
<th align="right">TN</th>
<th align="right">TP</th>
<th align="right">FP</th>
<th align="right">FN</th>
<th align="right">ner</th>
<th align="right">theta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">nb</td>
<td align="right">7877</td>
<td align="right">10</td>
<td align="right">123</td>
<td align="right">13</td>
<td align="right">1700</td>
<td align="right">0.15</td>
</tr>
<tr class="even">
<td align="left">rfs</td>
<td align="right">7885</td>
<td align="right">19</td>
<td align="right">115</td>
<td align="right">4</td>
<td align="right">2100</td>
<td align="right">0.20</td>
</tr>
<tr class="odd">
<td align="left">rfsq</td>
<td align="right">7814</td>
<td align="right">19</td>
<td align="right">186</td>
<td align="right">4</td>
<td align="right">2000</td>
<td align="right">0.15</td>
</tr>
<tr class="even">
<td align="left">knn</td>
<td align="right">7676</td>
<td align="right">23</td>
<td align="right">324</td>
<td align="right">0</td>
<td align="right">2100</td>
<td align="right">0.15</td>
</tr>
<tr class="odd">
<td align="left">knn</td>
<td align="right">7803</td>
<td align="right">21</td>
<td align="right">197</td>
<td align="right">2</td>
<td align="right">1700</td>
<td align="right">0.40</td>
</tr>
<tr class="even">
<td align="left">rfp</td>
<td align="right">7983</td>
<td align="right">11</td>
<td align="right">17</td>
<td align="right">12</td>
<td align="right">2100</td>
<td align="right">0.50</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="visualizing-performance" class="section level1">
<h1>Visualizing Performance</h1>
<div id="roc-receiver-operating-characteristic" class="section level2">
<h2>ROC: Receiver Operating Characteristic</h2>
<p><img src="/talk/maps-312018_files/figure-html/rocEX-1.png" width="672" /></p>
</div>
<div id="roc-fix-ner-vary-theta" class="section level2">
<h2>ROC: Fix ner, vary <span class="math inline">\(\theta\)</span></h2>
<p><img src="/talk/maps-312018_files/figure-html/rocTheta-1.png" width="672" /></p>
</div>
<div id="roc-fix-theta-vary-ner" class="section level2">
<h2>ROC: Fix <span class="math inline">\(\theta\)</span>, vary ner</h2>
<p><img src="/talk/maps-312018_files/figure-html/rocNER-1.png" width="672" /></p>
</div>
<div id="animated-roc" class="section level2">
<h2>Animated ROC</h2>
<div class="columns-2">
<div class="figure">
<img src="aniROC.gif" alt="aniroc" />
<p class="caption">aniroc</p>
</div>
<!--## Animated ROC, \theta = .25-->
<div class="figure">
<img src="aniROCft.gif" alt="anirocft" />
<p class="caption">anirocft</p>
</div>
</div>
</div>
<div id="roc-summary" class="section level2">
<h2>ROC Summary</h2>
<ul>
<li>Generally knn followed by some of the random forest models find the most cases of emergent reducibility</li>
<li>Higher theta, and higher class imbalance causes models to generally perform worse</li>
<li>exact changes depend on the model</li>
<li>Logistic Regression most susceptible to noise</li>
<li>see post on <a href="http://jpreszler.rbind.io" class="uri">http://jpreszler.rbind.io</a> to see comparison without regularization on logistic regression.</li>
<li>ROC helps compare models, theta threshold, and class imbalance</li>
<li>But which polynomials are found by each model?</li>
</ul>
</div>
<div id="heatmaps" class="section level2">
<h2>Heatmaps</h2>
<p><img src="/talk/maps-312018_files/figure-html/heatStatic-1.png" width="768" /></p>
</div>
<div id="animated-heatmaps" class="section level2">
<h2>Animated Heatmaps</h2>
<div class="figure">
<img src="ahm.gif" alt="" />

</div>
</div>
<div id="future-plans" class="section level2">
<h2>Future Plans</h2>
<p>-Model Critique:</p>
<pre><code>-Why are certain ER polynomials missed?
-Why are others found by certain models?
-Interpret KNN and RF models in context</code></pre>
<p>-Additional Models:</p>
<pre><code>-GAMs
-SVM
-xgboost</code></pre>
<p>-Use best models to improve search for ER and make conjectures</p>
</div>
</div>
